{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.2.1.tar.gz (165kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 5.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: wordcloud\n",
      "  Running setup.py bdist_wheel for wordcloud ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/29/9a/a9/86dcbbd5a7b6ace25887e4351a0136ea6dfcc0dd7de0a51357\n",
      "Successfully built wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "tqdm_pandas(tqdm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removeTag = lambda x : re.sub('<[^>]*>','',x)\n",
    "removeNewLine = lambda x: re.sub('\\\\n',' ', x)\n",
    "removePunc = lambda x: re.sub(\"[^a-zA-Z\\s]\",\"\",string.lower(x.translate(string.maketrans(\"\",\"\"), string.punctuation)))\n",
    "reduceSpaces = lambda x: re.sub(\"[\\s]{2,}\",\" \",x)\n",
    "\n",
    "def stripUnMeaningfulWords(sentance):\n",
    "    words = sentance.split(\" \")\n",
    "    newWorldList = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    return(string.join(newWorldList))\n",
    "\n",
    "removeUnwantedTag = lambda x : x.replace('please-remove-this-tag','')\n",
    "removeCommonWords = lambda x: x.replace('ive','').replace('im','')\n",
    "\n",
    "def wordCloudGenerator(column_heading):\n",
    "\n",
    "    wordcloud = WordCloud().generate(string.join(cooking_frame[column_heading].tolist()))\n",
    "    # lower max_font_size\n",
    "    #wordcloud = WordCloud().generate(text)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanContent(df, contentColumn):\n",
    "    df['content_clean'] = df[contentColumn].apply(removeTag).apply(removeNewLine).apply(removePunc).apply(reduceSpaces)\n",
    "    df['content_clean'] = df['content_clean'].progress_apply(stripUnMeaningfulWords)\n",
    "    df['content_clean'] = df['content_clean'].apply(removeCommonWords)\n",
    "    return df\n",
    "\n",
    "def cleanTags(df, tagColumn):\n",
    "    df['tags_clean'] = df['tags'].apply(removeUnwantedTag).apply(removeCommonWords)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cooking_frame = pd.read_csv('~/Data/cooking.csv')\n",
    "biology_frame = pd.read_csv('~/Data/biology.csv')\n",
    "crypto_frame = pd.read_csv('~/Data/crypto.csv')\n",
    "diy_frame = pd.read_csv('~/Data/diy.csv')\n",
    "robotics_frame = pd.read_csv('~/Data/robotics.csv')\n",
    "travel_frame = pd.read_csv('~/Data/travel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15404/15404 [02:45<00:00, 93.05it/s]\n",
      "100%|██████████| 13196/13196 [02:28<00:00, 88.79it/s]\n"
     ]
    }
   ],
   "source": [
    "cooking_frame = cleanContent(cooking_frame, 'content')\n",
    "biology_frame = cleanContent(biology_frame, 'content')\n",
    "#crypto_frame = cleanContent(crypto_frame, 'content')\n",
    "#diy_frame = cleanContent(diy_frame, 'content')\n",
    "#robotics_frame = cleanContent(robotics_frame, 'content')\n",
    "#travel_frame = cleanContent(travel_frame, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cooking_frame = cleanTags(cooking_frame, 'tags')\n",
    "biology_frame = cleanTags(biology_frame, 'tags')\n",
    "#crypto_frame = cleanTags(crypto_frame, 'tags')\n",
    "#diy_frame = cleanTags(diy_frame, 'tags')\n",
    "#robotics_frame = cleanTags(robotics_frame, 'tags')\n",
    "#travel_frame = cleanTags(travel_frame, 'tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [cooking_frame, biology_frame]\n",
    "#, crypto_frame, diy_frame, robotics_frame, travel_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overallFrame = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "        dtype=np.float32, encoding='utf-8', input='content',\n",
    "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
    "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "        tokenizer=None, vocabulary=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus = overallFrame['tags_clean'].tolist()\n",
    "Y = vectorizer.fit_transform(corpus)\n",
    "\n",
    "corpus = overallFrame['content_clean'].tolist()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#overallFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28600, 60045)\n",
      "(28600, 1407)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(X)\n",
    "\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=[WIDTH, HEIGHT, 3], activation='relu'))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(256, input_shape=[60045,], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1407))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 30\n",
    "batch_size = 32\n",
    "\n",
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28600/28600 [00:03<00:00, 8022.87it/s]\n",
      "100%|██████████| 28600/28600 [00:03<00:00, 8124.81it/s]\n"
     ]
    }
   ],
   "source": [
    "history = LossHistory()\n",
    "\n",
    "\n",
    "#train_x = np.array(train_x).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_y = np.array(train_y).astype(float)\n",
    "\n",
    "\n",
    "#test_x = [test[i] for i in range(len(test))]\n",
    "#test_x = np.array(test_x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.toarray()\n",
    "Y = Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28600 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-07f838fe21dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "train_x = [X[i,:] for i in tqdm(range(28600))]\n",
    "train_y = [Y[i,:] for i in tqdm(range(28600))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22880 samples, validate on 5720 samples\n",
      "Epoch 1/30\n",
      "22880/22880 [==============================] - 74s - loss: 0.1130 - acc: 0.9829 - val_loss: 0.0164 - val_acc: 0.9977\n",
      "Epoch 2/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0131 - acc: 0.9980 - val_loss: 0.0150 - val_acc: 0.9977\n",
      "Epoch 3/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0126 - acc: 0.9980 - val_loss: 0.0149 - val_acc: 0.9977\n",
      "Epoch 4/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0125 - acc: 0.9980 - val_loss: 0.0148 - val_acc: 0.9977\n",
      "Epoch 5/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0123 - acc: 0.9980 - val_loss: 0.0143 - val_acc: 0.9977\n",
      "Epoch 6/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0119 - acc: 0.9980 - val_loss: 0.0138 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0116 - acc: 0.9980 - val_loss: 0.0134 - val_acc: 0.9977\n",
      "Epoch 8/30\n",
      "22880/22880 [==============================] - 28s - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0132 - val_acc: 0.9977\n",
      "Epoch 9/30\n",
      "14080/22880 [=================>............] - ETA: 10s - loss: 0.0112 - acc: 0.9980"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              validation_split=0.20, verbose=1, shuffle=True, callbacks=[history, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = overallFrame['tags_clean'].tolist()\n",
    "\n",
    "print corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
